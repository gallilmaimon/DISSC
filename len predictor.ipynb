{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "from dataset import parse_manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "data_path = 'datasets/VCTK/hubert100'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup_seq(seq):\n",
    "    vals, counts = zip(*[(k, sum(1 for i in g)) for k,g in groupby(seq)])\n",
    "    return vals, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path, spk_id_dict):\n",
    "    names, seqs = parse_manifest(path)\n",
    "    speakers = [n.name.split('_')[0] for n in names]\n",
    "    \n",
    "    all_vals, all_counts, spk_ids = [], [], []\n",
    "    for name, seq in zip(speakers, seqs):\n",
    "        vals, counts = dedup_seq(seq)\n",
    "        all_vals.append(torch.IntTensor(vals))\n",
    "        all_counts.append(torch.FloatTensor(counts))\n",
    "        spk_ids.append(torch.IntTensor([spk_id_dict[name]]))\n",
    "    return pad_sequence(all_vals, batch_first=True, padding_value=100), pad_sequence(all_counts, batch_first=True, padding_value=-1), torch.concat(spk_ids).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spkrs_dict(path):\n",
    "    names, _ = parse_manifest(path)\n",
    "    speakers = [n.name.split('_')[0] for n in names]\n",
    "    spk_id_dict = {n:i for i, n in enumerate(np.unique(speakers))}\n",
    "    return spk_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LenDataset(Dataset):\n",
    "    def __init__(self, path, spk_id_dict):\n",
    "        self.vals, self.lens, self.spk_ids = prepare_dataset(path, spk_id_dict)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vals)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.vals[i], self.lens[i], self.spk_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LenPredictor(nn.Module):\n",
    "    def __init__(self, token_dict_size=100, spk_dict_size=199, emb_size=32):\n",
    "        super(LenPredictor, self).__init__()\n",
    "        \n",
    "        self.token_emb = nn.Embedding(token_dict_size + 1, emb_size, padding_idx=token_dict_size)\n",
    "        self.spk_emb = nn.Embedding(spk_dict_size + 1, emb_size, padding_idx=spk_dict_size)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.cnn1 = nn.Conv1d(2*emb_size, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.cnn11 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm1d(128)\n",
    "        self.cnn12 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.cnn2 = nn.Conv1d(128, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, seq, spk_id):\n",
    "        emb_seq = self.token_emb(seq)\n",
    "        emb_spk = torch.repeat_interleave(self.spk_emb(spk_id), seq.shape[-1], dim=1)\n",
    "        emb_seq = torch.cat([emb_seq, emb_spk], dim=-1)\n",
    "        \n",
    "        cnn1 = self.leaky(self.dropout(self.bn1(self.cnn1(emb_seq.transpose(1, 2)))))\n",
    "        cnn1 = self.leaky(self.dropout(self.bn11(self.cnn11(cnn1))))\n",
    "        cnn1 = self.leaky(self.dropout(self.bn12(self.cnn12(cnn1))))\n",
    "        return self.cnn2(cnn1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LenLoss(nn.Module):\n",
    "    def __init__(self, pad_idx=-1):\n",
    "        super(LenLoss, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, preds, lens):\n",
    "        mask = (lens != self.pad_idx)\n",
    "        total_loss = self.mse(preds, lens)        \n",
    "        return (mask * total_loss).sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_id_dict = get_spkrs_dict(f'{data_path}/train.txt')  # at the moment this doesn't support unseen speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = LenDataset(f'{data_path}/train.txt', spk_id_dict)\n",
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True)\n",
    "\n",
    "ds_val = LenDataset(f'{data_path}/val.txt', spk_id_dict)\n",
    "dl_val = DataLoader(ds_val, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LenPredictor(\n",
       "  (token_emb): Embedding(101, 32, padding_idx=100)\n",
       "  (spk_emb): Embedding(200, 32, padding_idx=199)\n",
       "  (leaky): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (cnn1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn11): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn12): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn2): Conv1d(128, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LenPredictor()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "len_loss = LenLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " finished: 99.92%, train loss: 2.288812\n",
      "total_train_loss: 2.88947\n",
      "total_val_loss: 2.28749\n",
      "\n",
      "Epoch: 1\n",
      " finished: 99.92%, train loss: 1.534668\n",
      "total_train_loss: 2.46791\n",
      "total_val_loss: 2.07699\n",
      "\n",
      "Epoch: 2\n",
      " finished: 99.92%, train loss: 1.338702\n",
      "total_train_loss: 2.35756\n",
      "total_val_loss: 1.96483\n",
      "\n",
      "Epoch: 3\n",
      " finished: 99.92%, train loss: 1.970320\n",
      "total_train_loss: 2.29910\n",
      "total_val_loss: 1.89826\n",
      "\n",
      "Epoch: 4\n",
      " finished: 99.92%, train loss: 1.730512\n",
      "total_train_loss: 2.25899\n",
      "total_val_loss: 1.88942\n",
      "\n",
      "Epoch: 5\n",
      " finished: 99.92%, train loss: 1.772251\n",
      "total_train_loss: 2.22439\n",
      "total_val_loss: 1.83305\n",
      "\n",
      "Epoch: 6\n",
      " finished: 99.92%, train loss: 1.285112\n",
      "total_train_loss: 2.20388\n",
      "total_val_loss: 1.82074\n",
      "\n",
      "Epoch: 7\n",
      " finished: 99.92%, train loss: 1.491398\n",
      "total_train_loss: 2.18589\n",
      "total_val_loss: 1.81707\n",
      "\n",
      "Epoch: 8\n",
      " finished: 99.92%, train loss: 1.370283\n",
      "total_train_loss: 2.17813\n",
      "total_val_loss: 1.80242\n",
      "\n",
      "Epoch: 9\n",
      " finished: 99.92%, train loss: 1.875250\n",
      "total_train_loss: 2.15425\n",
      "total_val_loss: 1.79382\n",
      "\n",
      "Epoch: 10\n",
      " finished: 99.92%, train loss: 1.808948\n",
      "total_train_loss: 2.14348\n",
      "total_val_loss: 1.78294\n",
      "\n",
      "Epoch: 11\n",
      " finished: 99.92%, train loss: 1.524533\n",
      "total_train_loss: 2.13201\n",
      "total_val_loss: 1.77768\n",
      "\n",
      "Epoch: 12\n",
      " finished: 99.92%, train loss: 1.696096\n",
      "total_train_loss: 2.12061\n",
      "total_val_loss: 1.76490\n",
      "\n",
      "Epoch: 13\n",
      " finished: 99.92%, train loss: 1.980055\n",
      "total_train_loss: 2.10996\n",
      "total_val_loss: 1.76632\n",
      "\n",
      "Epoch: 14\n",
      " finished: 99.92%, train loss: 1.514973\n",
      "total_train_loss: 2.10774\n",
      "total_val_loss: 1.77489\n",
      "\n",
      "Epoch: 15\n",
      " finished: 99.92%, train loss: 1.454008\n",
      "total_train_loss: 2.10161\n",
      "total_val_loss: 1.75530\n",
      "\n",
      "Epoch: 16\n",
      " finished: 99.92%, train loss: 1.739791\n",
      "total_train_loss: 2.09641\n",
      "total_val_loss: 1.74035\n",
      "\n",
      "Epoch: 17\n",
      " finished: 99.92%, train loss: 1.563719\n",
      "total_train_loss: 2.09022\n",
      "total_val_loss: 1.74373\n",
      "\n",
      "Epoch: 18\n",
      " finished: 99.92%, train loss: 1.592598\n",
      "total_train_loss: 2.08979\n",
      "total_val_loss: 1.73810\n",
      "\n",
      "Epoch: 19\n",
      " finished: 99.92%, train loss: 1.413539\n",
      "total_train_loss: 2.07721\n",
      "total_val_loss: 1.73714\n",
      "\n",
      "Epoch: 20\n",
      " finished: 99.92%, train loss: 4.422389\n",
      "total_train_loss: 2.08158\n",
      "total_val_loss: 1.74031\n",
      "\n",
      "Epoch: 21\n",
      " finished: 99.92%, train loss: 1.788603\n",
      "total_train_loss: 2.07792\n",
      "total_val_loss: 1.72690\n",
      "\n",
      "Epoch: 22\n",
      " finished: 99.92%, train loss: 1.457273\n",
      "total_train_loss: 2.06194\n",
      "total_val_loss: 1.71448\n",
      "\n",
      "Epoch: 23\n",
      " finished: 99.92%, train loss: 1.433486\n",
      "total_train_loss: 2.05396\n",
      "total_val_loss: 1.72016\n",
      "\n",
      "Epoch: 24\n",
      " finished: 99.92%, train loss: 1.704529\n",
      "total_train_loss: 2.06613\n",
      "total_val_loss: 1.71323\n",
      "\n",
      "Epoch: 25\n",
      " finished: 99.92%, train loss: 1.812500\n",
      "total_train_loss: 2.04993\n",
      "total_val_loss: 1.72027\n",
      "\n",
      "Epoch: 26\n",
      " finished: 99.92%, train loss: 1.534916\n",
      "total_train_loss: 2.05067\n",
      "total_val_loss: 1.70975\n",
      "\n",
      "Epoch: 27\n",
      " finished: 99.92%, train loss: 1.202955\n",
      "total_train_loss: 2.04746\n",
      "total_val_loss: 1.69754\n",
      "\n",
      "Epoch: 28\n",
      " finished: 99.92%, train loss: 1.529341\n",
      "total_train_loss: 2.04022\n",
      "total_val_loss: 1.70338\n",
      "\n",
      "Epoch: 29\n",
      " finished: 99.92%, train loss: 1.765475\n",
      "total_train_loss: 2.03568\n",
      "total_val_loss: 1.69574\n",
      "\n",
      "Epoch: 30\n",
      " finished: 99.92%, train loss: 1.932972\n",
      "total_train_loss: 2.04309\n",
      "total_val_loss: 1.70278\n",
      "\n",
      "Epoch: 31\n",
      " finished: 99.92%, train loss: 1.448405\n",
      "total_train_loss: 2.03751\n",
      "total_val_loss: 1.69285\n",
      "\n",
      "Epoch: 32\n",
      " finished: 99.92%, train loss: 2.971245\n",
      "total_train_loss: 2.02689\n",
      "total_val_loss: 1.69901\n",
      "\n",
      "Epoch: 33\n",
      " finished: 99.92%, train loss: 1.808686\n",
      "total_train_loss: 2.03607\n",
      "total_val_loss: 1.69463\n",
      "\n",
      "Epoch: 34\n",
      " finished: 99.92%, train loss: 1.708848\n",
      "total_train_loss: 2.02979\n",
      "total_val_loss: 1.68414\n",
      "\n",
      "Epoch: 35\n",
      " finished: 99.92%, train loss: 1.649428\n",
      "total_train_loss: 2.02594\n",
      "total_val_loss: 1.68621\n",
      "\n",
      "Epoch: 36\n",
      " finished: 99.92%, train loss: 5.737964\n",
      "total_train_loss: 2.02403\n",
      "total_val_loss: 1.68077\n",
      "\n",
      "Epoch: 37\n",
      " finished: 99.92%, train loss: 3.233307\n",
      "total_train_loss: 2.01956\n",
      "total_val_loss: 1.69803\n",
      "\n",
      "Epoch: 38\n",
      " finished: 99.92%, train loss: 4.520781\n",
      "total_train_loss: 2.01935\n",
      "total_val_loss: 1.68697\n",
      "\n",
      "Epoch: 39\n",
      " finished: 99.92%, train loss: 1.193739\n",
      "total_train_loss: 2.01701\n",
      "total_val_loss: 1.67606\n",
      "\n",
      "Epoch: 40\n",
      " finished: 99.92%, train loss: 1.535790\n",
      "total_train_loss: 2.01356\n",
      "total_val_loss: 1.70021\n",
      "\n",
      "Epoch: 41\n",
      " finished: 99.92%, train loss: 1.432075\n",
      "total_train_loss: 2.00903\n",
      "total_val_loss: 1.68141\n",
      "\n",
      "Epoch: 42\n",
      " finished: 99.92%, train loss: 1.207341\n",
      "total_train_loss: 2.02029\n",
      "total_val_loss: 1.66811\n",
      "\n",
      "Epoch: 43\n",
      " finished: 99.92%, train loss: 1.176438\n",
      "total_train_loss: 2.01259\n",
      "total_val_loss: 1.67065\n",
      "\n",
      "Epoch: 44\n",
      " finished: 99.92%, train loss: 1.547172\n",
      "total_train_loss: 2.01207\n",
      "total_val_loss: 1.66850\n",
      "\n",
      "Epoch: 45\n",
      " finished: 99.92%, train loss: 1.382363\n",
      "total_train_loss: 2.00692\n",
      "total_val_loss: 1.69122\n",
      "\n",
      "Epoch: 46\n",
      " finished: 99.92%, train loss: 1.619006\n",
      "total_train_loss: 2.00158\n",
      "total_val_loss: 1.68015\n",
      "\n",
      "Epoch: 47\n",
      " finished: 99.92%, train loss: 1.347500\n",
      "total_train_loss: 2.00538\n",
      "total_val_loss: 1.68202\n",
      "\n",
      "Epoch: 48\n",
      " finished: 99.92%, train loss: 1.753568\n",
      "total_train_loss: 2.00538\n",
      "total_val_loss: 1.67488\n",
      "\n",
      "Epoch: 49\n",
      " finished: 99.92%, train loss: 0.987206\n",
      "total_train_loss: 2.00178\n",
      "total_val_loss: 1.67685\n",
      "\n",
      "Epoch: 50\n",
      " finished: 99.92%, train loss: 1.666539\n",
      "total_train_loss: 1.99250\n",
      "total_val_loss: 1.67847\n",
      "\n",
      "Epoch: 51\n",
      " finished: 99.92%, train loss: 1.772688\n",
      "total_train_loss: 2.00382\n",
      "total_val_loss: 1.68901\n",
      "\n",
      "Epoch: 52\n",
      " finished: 99.92%, train loss: 1.264823\n",
      "total_train_loss: 2.00294\n",
      "total_val_loss: 1.67753\n",
      "\n",
      "Epoch: 53\n",
      " finished: 99.92%, train loss: 1.445430\n",
      "total_train_loss: 1.99738\n",
      "total_val_loss: 1.68305\n",
      "\n",
      "Epoch: 54\n",
      " finished: 99.92%, train loss: 1.315654\n",
      "total_train_loss: 1.98992\n",
      "total_val_loss: 1.67924\n",
      "\n",
      "Epoch: 55\n",
      " finished: 99.92%, train loss: 1.869445\n",
      "total_train_loss: 1.99579\n",
      "total_val_loss: 1.66647\n",
      "\n",
      "Epoch: 56\n",
      " finished: 22.57%, train loss: 1.540770"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29081/3077399979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    \n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for i, batch in enumerate(dl_train):\n",
    "        seqs, lens, spk_id = batch\n",
    "        seqs = seqs.to(device)\n",
    "        lens = lens.to(device)\n",
    "        spk_id = spk_id.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(seqs, spk_id)\n",
    "        loss = len_loss(preds, lens)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_train_loss += loss\n",
    "\n",
    "        print(f'\\r finished: {100*i/len(dl_train):.2f}%, train loss: {loss:.5f}', end='')\n",
    "    \n",
    "    # validation \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    for i, batch in enumerate(dl_val):\n",
    "        seqs, lens, spk_id = batch\n",
    "        seqs = seqs.to(device)\n",
    "        lens = lens.to(device)\n",
    "        spk_id = spk_id.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(seqs, spk_id)\n",
    "            loss = len_loss(preds, lens)\n",
    "        total_val_loss += loss\n",
    "    \n",
    "    print(f'\\ntotal_train_loss: {total_train_loss/len(dl_train):.5f}')\n",
    "    print(f'total_val_loss: {total_val_loss/len(dl_val):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds, total_lens = [], []\n",
    "# infer \n",
    "model.eval()\n",
    "for i, batch in enumerate(dl_val):\n",
    "    seqs, lens, spk_id = batch\n",
    "    seqs = seqs.to(device)\n",
    "    lens = lens.to(device)\n",
    "    spk_id = spk_id.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(seqs, spk_id)\n",
    "    total_preds.append(preds)\n",
    "    total_lens.append(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds = torch.cat(total_preds)\n",
    "total_lens = torch.cat(total_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11, device='cuda:0')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_diff = (torch.round(torch.clip(total_preds, 1)) - total_lens).abs()[total_lens != 100]\n",
    "# rel_diff = (torch.round(total_preds) - total_lens).abs()[total_lens != 100]\n",
    "(rel_diff >= 35).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.7446e+04, 6.4358e+04, 9.5530e+03, 3.0730e+03, 1.3600e+03,\n",
       "        0.0000e+00, 7.1500e+02, 4.5200e+02, 2.5400e+02, 1.8200e+02,\n",
       "        1.2500e+02, 0.0000e+00, 7.7000e+01, 6.0000e+01, 4.9000e+01,\n",
       "        3.6000e+01, 2.1000e+01, 0.0000e+00, 1.4000e+01, 1.1000e+01,\n",
       "        1.2000e+01, 9.0000e+00, 7.0000e+00, 0.0000e+00, 4.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 1.0000e+00, 4.0000e+00, 0.0000e+00,\n",
       "        3.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([ 0.  ,  0.83,  1.66,  2.49,  3.32,  4.15,  4.98,  5.81,  6.64,\n",
       "         7.47,  8.3 ,  9.13,  9.96, 10.79, 11.62, 12.45, 13.28, 14.11,\n",
       "        14.94, 15.77, 16.6 , 17.43, 18.26, 19.09, 19.92, 20.75, 21.58,\n",
       "        22.41, 23.24, 24.07, 24.9 , 25.73, 26.56, 27.39, 28.22, 29.05,\n",
       "        29.88, 30.71, 31.54, 32.37, 33.2 , 34.03, 34.86, 35.69, 36.52,\n",
       "        37.35, 38.18, 39.01, 39.84, 40.67, 41.5 , 42.33, 43.16, 43.99,\n",
       "        44.82, 45.65, 46.48, 47.31, 48.14, 48.97, 49.8 , 50.63, 51.46,\n",
       "        52.29, 53.12, 53.95, 54.78, 55.61, 56.44, 57.27, 58.1 , 58.93,\n",
       "        59.76, 60.59, 61.42, 62.25, 63.08, 63.91, 64.74, 65.57, 66.4 ,\n",
       "        67.23, 68.06, 68.89, 69.72, 70.55, 71.38, 72.21, 73.04, 73.87,\n",
       "        74.7 , 75.53, 76.36, 77.19, 78.02, 78.85, 79.68, 80.51, 81.34,\n",
       "        82.17, 83.  ], dtype=float32),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rel_diff.cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25., 25., 29., 35., 42., 37., 25., 32., 43., 74., 64., 29., 36.,\n",
       "       28., 39., 74., 29., 40., 28., 83.], dtype=float32)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rel_diff.cpu().numpy()\n",
    "a[np.argpartition(a, -20)[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29., 30., 31., 32., 33., 34., 37., 41., 42., 43., 46.,\n",
       "        47., 49., 79., 81., 82., 87.], dtype=float32),\n",
       " array([89056, 50864, 17957,  9052,  4681,  2055,  1187,   785,   544,\n",
       "          362,   251,   218,   161,   134,   100,    84,    59,    56,\n",
       "           46,    41,    28,    32,    16,    15,    12,     9,     4,\n",
       "            6,     5,     1,     6,     2,     3,     1,     1,     1,\n",
       "            1,     1,     2,     1,     1,     1,     1,     1,     1]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "np.unique(total_lens[total_lens != 100].cpu().numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.052786, 22.219421, 22.324633, 22.708384, 22.726074, 22.951706,\n",
       "       27.996572, 31.15078 , 26.92656 , 24.947197], dtype=float32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = total_preds[total_lens != 100].cpu().numpy()\n",
    "a[np.argpartition(a, -10)[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5008, device='cuda:0')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_lens[total_lens != 100] == 1).sum()/ len(rel_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "         23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "         34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "         45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "         56.,  57.,  58.,  59.,  60.,  62.,  63.,  64.,  65.,  66.,  67.,\n",
       "         68.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,\n",
       "         80.,  82.,  84.,  85.,  87.,  88.,  89.,  90.,  91.,  92.,  94.,\n",
       "         95.,  98., 100., 101., 103., 105., 106., 107., 108., 111., 116.,\n",
       "        119., 120., 122., 123., 125., 133., 139., 142., 146., 149., 154.,\n",
       "        159., 166., 184., 242., 243., 365.], dtype=float32),\n",
       " array([ 1630662,   934798,   332029,   163104,    86254,    37399,\n",
       "           22184,    14335,     9788,     6918,     5161,     3964,\n",
       "            2987,     2375,     1833,     1540,     1285,     1000,\n",
       "             784,      688,      532,      434,      376,      303,\n",
       "             241,      170,      133,      127,       84,       53,\n",
       "              52,       43,       41,       36,       29,       16,\n",
       "              24,       26,       14,       17,       18,       13,\n",
       "              15,       10,       12,       11,       13,       13,\n",
       "               5,        5,        6,        4,        5,        5,\n",
       "               6,        1,        8,        6,        4,        3,\n",
       "               2,        3,        4,        3,        2,        6,\n",
       "               2,        3,        2,        3,        5,        2,\n",
       "               1,        1,        1,        4,        1,        1,\n",
       "               2,        2,        1,        1,        1,        2,\n",
       "               1,        1,        2,        1,        1,        5,\n",
       "        11489157,        2,        1,        1,        2,        1,\n",
       "               1,        2,        1,        1,        1,        1,\n",
       "               1,        2,        1,        1,        2,        1,\n",
       "               1,        2,        1,        1,        1,        1,\n",
       "               1,        1]))"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ds_train.lens.numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2174, 312])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
