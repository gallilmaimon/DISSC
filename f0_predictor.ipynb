{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "from dataset import parse_manifest, get_yaapt_f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "data_path = '.'  # 'datasets/VCTK/hubert100'\n",
    "f0_path = 'datasets/VCTK/f0_stats.th'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_spkrs_dict(path):\n",
    "#     names, _ = parse_manifest(path)\n",
    "#     speakers = [n.name.split('_')[0] for n in names]\n",
    "#     spk_id_dict = {n:i for i, n in enumerate(np.unique(speakers))}\n",
    "#     return spk_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spkrs_dict(path):\n",
    "    speakers = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            val_dict = eval(line)\n",
    "            speakers.append(val_dict['audio'].split('_')[0])\n",
    "    return {n:i for i, n in enumerate(np.unique(speakers))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_pool_1d(arr, pool_size):\n",
    "#     arr = arr.reshape(-1, pool_size)\n",
    "#     return arr.mean(axis=1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# import tqdm\n",
    "\n",
    "# def parse_audio(p, spk_id_dict, f0_param_dict):\n",
    "#     aud, _ = sf.read(p)\n",
    "#     spk_id = spk_id_dict[p.name.split('_')[0]]\n",
    "#     f0 = get_yaapt_f0(aud.reshape((1, 1, -1)))\n",
    "#     return torch.from_numpy((f0 - f0_param_dict[spk_id]['f0_mean'])/f0_param_dict[spk_id]['f0_std']).view(-1), torch.IntTensor([spk_id])\n",
    "    \n",
    "\n",
    "# def prepare_dataset(path, spk_id_dict, f0_param_dict):\n",
    "#     paths, seqs = parse_manifest(path)\n",
    "#     seqs = [torch.from_numpy(s) for s in seqs]\n",
    "#     seqs = seqs[:1]\n",
    "#     paths = paths[:1]\n",
    "#     with Pool() as p:\n",
    "#         fs, spk_ids = zip(*list(tqdm.tqdm(p.imap(partial(parse_audio, spk_id_dict=spk_id_dict, f0_param_dict=f0_param_dict), paths), total=len(paths))))\n",
    "#     fs = list(fs)\n",
    "#     for i in range(len(seqs)):\n",
    "#         fs[i] = mean_pool_1d(fs[i][:len(seqs[i])*4], 4)\n",
    "#     return pad_sequence(seqs, batch_first=True, padding_value=100), pad_sequence(fs, batch_first=True, padding_value=100), torch.concat(spk_ids).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path, spk_id_dict, f0_param_dict):\n",
    "    fs, seqs, spk_ids = [], [], []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            val_dict = eval(line)\n",
    "            seqs.append(torch.IntTensor(val_dict['units']))\n",
    "            fs.append(torch.FloatTensor(val_dict['f0']))\n",
    "            name = val_dict['audio'].split('_')[0]\n",
    "            spk_ids.append(torch.IntTensor([spk_id_dict[name]]))\n",
    "    return pad_sequence(seqs, batch_first=True, padding_value=100), pad_sequence(fs, batch_first=True, padding_value=100), torch.concat(spk_ids).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 0.001\n",
    "\n",
    "def get_scaling(fs, nbins=50, f_min=None, scale=None):\n",
    "    if f_min is None:\n",
    "        f_min = fs.min()\n",
    "    if scale is None:\n",
    "        scale = (fs.max() + EPS - f_min)/nbins\n",
    "    return f_min, scale\n",
    "\n",
    "def quantise_f0(fs, nbins=50, f_min=None, scale=None):\n",
    "    if f_min is None:\n",
    "        f_min = fs.min()\n",
    "    if scale is None:\n",
    "        scale = (fs.max() + EPS - f_min)/nbins\n",
    "    q_fs = torch.clip(torch.div(fs - f_min, scale, rounding_mode='floor').type(torch.LongTensor), min=0, max=nbins-1)\n",
    "    return nn.functional.one_hot(q_fs, num_classes=nbins), f_min, scale\n",
    "\n",
    "def prepare_f0(fs, nbins=50, f_min=None, scale=None):\n",
    "    res = torch.zeros((fs.shape[0], fs.shape[1], nbins)).long()\n",
    "    res[fs!=100], fmin, scale = quantise_f0(fs[fs!=100], nbins, f_min, scale)\n",
    "    \n",
    "    filt = GaussianBlur(kernel_size=(5, 1), sigma=0.5)\n",
    "    res = filt(res.float())\n",
    "    res[fs==100] = -1\n",
    "    return res, fmin, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchDataset(Dataset):\n",
    "    def __init__(self, path, spk_id_dict, f0_param_dict, nbins=50, f_min=None, scale=None):\n",
    "        self.vals, self.fs, self.spk_ids = prepare_dataset(path, spk_id_dict, f0_param_dict)\n",
    "#         self.fs1, self.f_min, self.scale = prepare_f0(self.fs, nbins, f_min, scale)\n",
    "        self.f_min, self.scale = get_scaling(self.fs, nbins, f_min, scale)\n",
    "        self.nbins = nbins\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vals)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "#         return self.vals[i], self.fs1[i], self.fs[i], self.spk_ids[i]\n",
    "        return self.vals[i], self.fs[i], self.spk_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchPredictor(nn.Module):\n",
    "    def __init__(self, token_dict_size=100, spk_dict_size=199, emb_size=32, nbins=50):\n",
    "        super(PitchPredictor, self).__init__()\n",
    "        self.nbins = nbins\n",
    "        self.token_emb = nn.Embedding(token_dict_size + 1, emb_size, padding_idx=token_dict_size)\n",
    "        self.spk_emb = nn.Embedding(spk_dict_size + 1, emb_size, padding_idx=spk_dict_size)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        \n",
    "        self.cnn1 = nn.Conv1d(2*emb_size, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.cnn11 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm1d(128)\n",
    "        self.cnn12 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.cnn2 = nn.Conv1d(128, nbins, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, seq, spk_id):\n",
    "        emb_seq = self.token_emb(seq)\n",
    "        emb_spk = torch.repeat_interleave(self.spk_emb(spk_id), seq.shape[-1], dim=1)\n",
    "        emb_seq = torch.cat([emb_seq, emb_spk], dim=-1)\n",
    "        \n",
    "        cnn1 = self.leaky(self.dropout(self.bn1(self.cnn1(emb_seq.transpose(1, 2)))))\n",
    "        cnn1 = self.leaky(self.dropout(self.bn11(self.cnn11(cnn1))))\n",
    "        cnn1 = self.leaky(self.dropout(self.bn12(self.cnn12(cnn1))))\n",
    "        return self.cnn2(cnn1).squeeze(1)\n",
    "    \n",
    "    def infer_norm_freq(self, seq, spk_id, fmin, scale):\n",
    "        preds = torch.sigmoid(self(seq, spk_id).transpose(1, 2))  # calculate class probs\n",
    "        f_weights = torch.linspace(fmin + 0.5 * scale, fmin + (self.nbins - 0.5) * scale, self.nbins)\n",
    "        return torch.inner(preds, f_weights)\n",
    "    \n",
    "    def calc_norm_freq(self, preds, fmin, scale):\n",
    "        preds = torch.sigmoid(preds.transpose(1, 2))  # calculate class probs\n",
    "        f_weights = torch.linspace(fmin + 0.5 * scale, fmin + (self.nbins - 0.5) * scale, self.nbins)\n",
    "        return torch.inner(preds, f_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PitchLoss(nn.Module):\n",
    "#     def __init__(self, pad_idx=-1):\n",
    "#         super(PitchLoss, self).__init__()\n",
    "#         self.pad_idx = pad_idx\n",
    "#         self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "#     def forward(self, preds, gt):\n",
    "#         mask = (gt != self.pad_idx)\n",
    "#         total_loss = self.bce(preds, gt)        \n",
    "#         return (mask * total_loss).sum() / mask.sum()\n",
    "\n",
    "class PitchLoss(nn.Module):\n",
    "    def __init__(self, f_min, scale, nbins, pad_idx=-1):\n",
    "        super(PitchLoss, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.f_min = f_min\n",
    "        self.scale = scale\n",
    "        self.nbins = nbins\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "    def forward(self, preds, gt):\n",
    "        gt, _, _ = prepare_f0(gt, self.nbins, self.f_min, self.scale)\n",
    "        mask = (gt != self.pad_idx)\n",
    "        total_loss = self.bce(preds, gt)        \n",
    "        return (mask * total_loss).sum() / mask.sum()\n",
    "    \n",
    "class PitchRegLoss(nn.Module):\n",
    "    def __init__(self, pad_idx=100):\n",
    "        super(PitchRegLoss, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, preds, gts):\n",
    "        mask = (gts != self.pad_idx)\n",
    "        total_loss = self.mse(preds, gts)        \n",
    "        return (mask * total_loss).sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_param_dict = torch.load(f0_path)\n",
    "spk_id_dict = get_spkrs_dict(f'{data_path}/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = PitchDataset(f'{data_path}/train.txt', spk_id_dict, f0_param_dict, nbins=50)\n",
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True)\n",
    "\n",
    "ds_val = PitchDataset(f'{data_path}/val.txt', spk_id_dict, f0_param_dict, nbins=ds_train.nbins, f_min=ds_train.f_min, scale=ds_train.scale)\n",
    "dl_val = DataLoader(ds_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PitchPredictor(\n",
       "  (token_emb): Embedding(101, 32, padding_idx=100)\n",
       "  (spk_emb): Embedding(200, 32, padding_idx=199)\n",
       "  (leaky): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (cnn1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn11): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn12): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn2): Conv1d(128, 50, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PitchPredictor(nbins=50)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "pitch_loss = PitchLoss(ds_train.f_min, ds_train.scale, ds_train.nbins)\n",
    "reg_loss = PitchRegLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_train = dl_val\n",
    "# ds_train = ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " finished: 99.90%, train loss: 0.06771\n",
      "total_train_loss: 0.05443, train MSE: 194573.07812\n",
      "total_val_loss: 0.04092, val MSE: 1772.62000\n",
      "\n",
      "Epoch: 1\n",
      " finished: 99.90%, train loss: 0.05906\n",
      "total_train_loss: 0.04041, train MSE: 1682.88159\n",
      "total_val_loss: 0.03941, val MSE: 1387.76257\n",
      "\n",
      "Epoch: 2\n",
      " finished: 99.90%, train loss: 0.05162\n",
      "total_train_loss: 0.03949, train MSE: 1343.99573\n",
      "total_val_loss: 0.03900, val MSE: 1339.63123\n",
      "\n",
      "Epoch: 3\n",
      " finished: 99.90%, train loss: 0.04731\n",
      "total_train_loss: 0.03907, train MSE: 1224.34924\n",
      "total_val_loss: 0.03881, val MSE: 1215.50439\n",
      "\n",
      "Epoch: 4\n",
      " finished: 99.90%, train loss: 0.04696\n",
      "total_train_loss: 0.03882, train MSE: 1174.66016\n",
      "total_val_loss: 0.03863, val MSE: 1222.37939\n",
      "\n",
      "Epoch: 5\n",
      " finished: 99.90%, train loss: 0.07348\n",
      "total_train_loss: 0.03869, train MSE: 1156.67810\n",
      "total_val_loss: 0.03851, val MSE: 1265.03882\n",
      "\n",
      "Epoch: 6\n",
      " finished: 99.90%, train loss: 0.03669\n",
      "total_train_loss: 0.03853, train MSE: 1139.99341\n",
      "total_val_loss: 0.03839, val MSE: 1186.38586\n",
      "\n",
      "Epoch: 7\n",
      " finished: 99.90%, train loss: 0.08318\n",
      "total_train_loss: 0.03845, train MSE: 1116.65295\n",
      "total_val_loss: 0.03845, val MSE: 1099.32043\n",
      "\n",
      "Epoch: 8\n",
      " finished: 99.90%, train loss: 0.06871\n",
      "total_train_loss: 0.03839, train MSE: 1111.33252\n",
      "total_val_loss: 0.03831, val MSE: 1310.67334\n",
      "\n",
      "Epoch: 9\n",
      " finished: 99.90%, train loss: 0.05254\n",
      "total_train_loss: 0.03829, train MSE: 1103.41443\n",
      "total_val_loss: 0.03808, val MSE: 1116.16296\n",
      "\n",
      "Epoch: 10\n",
      " finished: 99.90%, train loss: 0.03960\n",
      "total_train_loss: 0.03822, train MSE: 1085.22290\n",
      "total_val_loss: 0.03819, val MSE: 1116.83630\n",
      "\n",
      "Epoch: 11\n",
      " finished: 99.90%, train loss: 0.04254\n",
      "total_train_loss: 0.03816, train MSE: 1078.31384\n",
      "total_val_loss: 0.03798, val MSE: 1050.67078\n",
      "\n",
      "Epoch: 12\n",
      " finished: 99.90%, train loss: 0.03931\n",
      "total_train_loss: 0.03810, train MSE: 1068.98425\n",
      "total_val_loss: 0.03795, val MSE: 1064.65881\n",
      "\n",
      "Epoch: 13\n",
      " finished: 99.90%, train loss: 0.03416\n",
      "total_train_loss: 0.03806, train MSE: 1066.77917\n",
      "total_val_loss: 0.03796, val MSE: 1050.12317\n",
      "\n",
      "Epoch: 14\n",
      " finished: 99.90%, train loss: 0.04873\n",
      "total_train_loss: 0.03803, train MSE: 1062.39478\n",
      "total_val_loss: 0.03796, val MSE: 1052.46045\n",
      "\n",
      "Epoch: 15\n",
      " finished: 99.90%, train loss: 0.04601\n",
      "total_train_loss: 0.03800, train MSE: 1059.28674\n",
      "total_val_loss: 0.03790, val MSE: 1068.74365\n",
      "\n",
      "Epoch: 16\n",
      " finished: 99.90%, train loss: 0.05119\n",
      "total_train_loss: 0.03799, train MSE: 1058.42700\n",
      "total_val_loss: 0.03795, val MSE: 1049.89587\n",
      "\n",
      "Epoch: 17\n",
      " finished: 99.90%, train loss: 0.04242\n",
      "total_train_loss: 0.03795, train MSE: 1054.85571\n",
      "total_val_loss: 0.03790, val MSE: 1104.60376\n",
      "\n",
      "Epoch: 18\n",
      " finished: 99.90%, train loss: 0.06385\n",
      "total_train_loss: 0.03793, train MSE: 1051.85974\n",
      "total_val_loss: 0.03795, val MSE: 1045.21887\n",
      "\n",
      "Epoch: 19\n",
      " finished: 99.90%, train loss: 0.03758\n",
      "total_train_loss: 0.03789, train MSE: 1054.81091\n",
      "total_val_loss: 0.03791, val MSE: 1132.83850\n",
      "\n",
      "Epoch: 20\n",
      " finished: 99.90%, train loss: 0.05517\n",
      "total_train_loss: 0.03788, train MSE: 1051.33740\n",
      "total_val_loss: 0.03786, val MSE: 1055.57385\n",
      "\n",
      "Epoch: 21\n",
      " finished: 99.90%, train loss: 0.05977\n",
      "total_train_loss: 0.03787, train MSE: 1052.54041\n",
      "total_val_loss: 0.03789, val MSE: 1116.45105\n",
      "\n",
      "Epoch: 22\n",
      " finished: 99.90%, train loss: 0.04836\n",
      "total_train_loss: 0.03784, train MSE: 1050.62097\n",
      "total_val_loss: 0.03782, val MSE: 1041.48157\n",
      "\n",
      "Epoch: 23\n",
      " finished: 99.90%, train loss: 0.04194\n",
      "total_train_loss: 0.03781, train MSE: 1042.68018\n",
      "total_val_loss: 0.03782, val MSE: 1048.50842\n",
      "\n",
      "Epoch: 24\n",
      " finished: 96.68%, train loss: 0.03762"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " finished: 99.76%, train loss: 0.04000\n",
      "total_train_loss: 0.03820, train MSE: 1100.38123\n",
      "total_val_loss: 0.03798, val MSE: 1061.28638\n",
      "\n",
      "Epoch: 1\n",
      " finished: 99.76%, train loss: 0.03668\n",
      "total_train_loss: 0.03815, train MSE: 1093.88330\n",
      "total_val_loss: 0.03794, val MSE: 1094.55273\n",
      "\n",
      "Epoch: 2\n",
      " finished: 99.76%, train loss: 0.03792\n",
      "total_train_loss: 0.03810, train MSE: 1086.51672\n",
      "total_val_loss: 0.03795, val MSE: 1086.67590\n",
      "\n",
      "Epoch: 3\n",
      " finished: 99.76%, train loss: 0.03787\n",
      "total_train_loss: 0.03804, train MSE: 1082.90088\n",
      "total_val_loss: 0.03787, val MSE: 1058.09058\n",
      "\n",
      "Epoch: 4\n",
      " finished: 99.76%, train loss: 0.03737\n",
      "total_train_loss: 0.03802, train MSE: 1081.33630\n",
      "total_val_loss: 0.03778, val MSE: 1042.58691\n",
      "\n",
      "Epoch: 5\n",
      " finished: 99.76%, train loss: 0.03698\n",
      "total_train_loss: 0.03797, train MSE: 1075.89636\n",
      "total_val_loss: 0.03776, val MSE: 1031.78772\n",
      "\n",
      "Epoch: 6\n",
      " finished: 99.76%, train loss: 0.03707\n",
      "total_train_loss: 0.03793, train MSE: 1069.02795\n",
      "total_val_loss: 0.03768, val MSE: 1039.17578\n",
      "\n",
      "Epoch: 7\n",
      " finished: 99.76%, train loss: 0.03894\n",
      "total_train_loss: 0.03790, train MSE: 1073.01514\n",
      "total_val_loss: 0.03768, val MSE: 1038.69824\n",
      "\n",
      "Epoch: 8\n",
      " finished: 99.76%, train loss: 0.03896\n",
      "total_train_loss: 0.03786, train MSE: 1069.49536\n",
      "total_val_loss: 0.03762, val MSE: 1026.60559\n",
      "\n",
      "Epoch: 9\n",
      " finished: 99.76%, train loss: 0.03991\n",
      "total_train_loss: 0.03782, train MSE: 1061.38599\n",
      "total_val_loss: 0.03761, val MSE: 1049.78601\n",
      "\n",
      "Epoch: 10\n",
      " finished: 99.76%, train loss: 0.03881\n",
      "total_train_loss: 0.03780, train MSE: 1060.80139\n",
      "total_val_loss: 0.03757, val MSE: 1049.37085\n",
      "\n",
      "Epoch: 11\n",
      " finished: 99.76%, train loss: 0.03800\n",
      "total_train_loss: 0.03777, train MSE: 1061.14124\n",
      "total_val_loss: 0.03756, val MSE: 1036.92798\n",
      "\n",
      "Epoch: 12\n",
      " finished: 99.76%, train loss: 0.03870\n",
      "total_train_loss: 0.03775, train MSE: 1056.55579\n",
      "total_val_loss: 0.03750, val MSE: 1012.91351\n",
      "\n",
      "Epoch: 13\n",
      " finished: 99.76%, train loss: 0.03838\n",
      "total_train_loss: 0.03771, train MSE: 1052.09863\n",
      "total_val_loss: 0.03749, val MSE: 1017.63623\n",
      "\n",
      "Epoch: 14\n",
      " finished: 99.76%, train loss: 0.03686\n",
      "total_train_loss: 0.03769, train MSE: 1054.09021\n",
      "total_val_loss: 0.03745, val MSE: 1020.93152\n",
      "\n",
      "Epoch: 15\n",
      " finished: 99.76%, train loss: 0.03614\n",
      "total_train_loss: 0.03767, train MSE: 1050.06177\n",
      "total_val_loss: 0.03743, val MSE: 1025.10669\n",
      "\n",
      "Epoch: 16\n",
      " finished: 99.76%, train loss: 0.03784\n",
      "total_train_loss: 0.03766, train MSE: 1051.33545\n",
      "total_val_loss: 0.03744, val MSE: 1013.96033\n",
      "\n",
      "Epoch: 17\n",
      " finished: 99.76%, train loss: 0.03924\n",
      "total_train_loss: 0.03762, train MSE: 1050.84375\n",
      "total_val_loss: 0.03737, val MSE: 1017.34021\n",
      "\n",
      "Epoch: 18\n",
      " finished: 99.76%, train loss: 0.03923\n",
      "total_train_loss: 0.03759, train MSE: 1045.95447\n",
      "total_val_loss: 0.03741, val MSE: 1010.55432\n",
      "\n",
      "Epoch: 19\n",
      " finished: 99.76%, train loss: 0.03677\n",
      "total_train_loss: 0.03758, train MSE: 1044.84412\n",
      "total_val_loss: 0.03736, val MSE: 1007.98676\n",
      "\n",
      "Epoch: 20\n",
      " finished: 99.76%, train loss: 0.03839\n",
      "total_train_loss: 0.03756, train MSE: 1046.23853\n",
      "total_val_loss: 0.03732, val MSE: 1007.23395\n",
      "\n",
      "Epoch: 21\n",
      " finished: 99.76%, train loss: 0.04012\n",
      "total_train_loss: 0.03755, train MSE: 1045.29187\n",
      "total_val_loss: 0.03734, val MSE: 1011.85327\n",
      "\n",
      "Epoch: 22\n",
      " finished: 54.77%, train loss: 0.03580"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1738403/1565910917.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mopt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mpreds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseqs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspk_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpitch_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgts_cls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_1738403/2442313915.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, seq, spk_id)\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0mcnn1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleaky\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcnn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0memb_seq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0mcnn1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleaky\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn11\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcnn11\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcnn1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mcnn1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleaky\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn12\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcnn12\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcnn1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcnn2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcnn1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vc/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    295\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    296\u001B[0m                             _single(0), self.dilation, self.groups)\n\u001B[0;32m--> 297\u001B[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    298\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_mse = 0\n",
    "    for i, batch in enumerate(dl_train):\n",
    "        seqs, gts_reg, spk_id = batch\n",
    "        seqs = seqs.to(device)\n",
    "        gts_reg = gts_reg.to(device)\n",
    "        spk_id = spk_id.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(seqs, spk_id)\n",
    "        loss = pitch_loss(preds.transpose(1,2), gts_reg)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_train_loss += loss\n",
    "        total_train_mse += reg_loss(model.calc_norm_freq(preds, ds_train.f_min, ds_train.scale), gts_reg)\n",
    "\n",
    "        print(f'\\r finished: {100*i/len(dl_train):.2f}%, train loss: {loss:.5f}', end='')\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_mse = 0\n",
    "    for i, batch in enumerate(dl_val):\n",
    "        seqs, gts_reg, spk_id = batch\n",
    "        seqs = seqs.to(device)\n",
    "        gts_reg = gts_reg.to(device)\n",
    "        spk_id = spk_id.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(seqs, spk_id)\n",
    "            loss = pitch_loss(preds.transpose(1,2), gts_reg)\n",
    "        total_val_loss += loss\n",
    "        total_val_mse += reg_loss(model.calc_norm_freq(preds, ds_val.f_min, ds_val.scale), gts_reg)\n",
    "\n",
    "    print(f'\\ntotal_train_loss: {total_train_loss/len(dl_train):.5f}, train MSE: {total_train_mse/len(dl_train):.5f}')\n",
    "    print(f'total_val_loss: {total_val_loss/len(dl_val):.5f}, val MSE: {total_val_mse/len(dl_val):.5f}')\n",
    "for epoch in range(100):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    \n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_mse = 0\n",
    "    for i, batch in enumerate(dl_train):\n",
    "        seqs, gts_cls, gts_reg, spk_id = batch\n",
    "        seqs = seqs.to(device)\n",
    "        gts_cls = gts_cls.to(device)\n",
    "        gts_reg = gts_reg.to(device)\n",
    "        spk_id = spk_id.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(seqs, spk_id)\n",
    "        loss = pitch_loss(preds, gts_cls.transpose(1,2))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_train_loss += loss\n",
    "        total_train_mse += reg_loss(model.calc_norm_freq(preds, ds_train.f_min, ds_train.scale), gts_reg)\n",
    "        \n",
    "        print(f'\\r finished: {100*i/len(dl_train):.2f}%, train loss: {loss:.5f}', end='')\n",
    "    \n",
    "    # validation \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_mse = 0\n",
    "    for i, batch in enumerate(dl_val):\n",
    "        seqs, gts_cls, gts_reg, spk_id = batch\n",
    "        seqs = seqs.to(device)\n",
    "        gts_cls = gts_cls.to(device)\n",
    "        gts_reg = gts_reg.to(device)\n",
    "        spk_id = spk_id.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(seqs, spk_id)\n",
    "            loss = pitch_loss(preds, gts_cls.transpose(1,2))\n",
    "        total_val_loss += loss\n",
    "        total_val_mse += reg_loss(model.calc_norm_freq(preds, ds_val.f_min, ds_val.scale), gts_reg)\n",
    "        \n",
    "    print(f'\\ntotal_train_loss: {total_train_loss/len(dl_train):.5f}, train MSE: {total_train_mse/len(dl_train):.5f}')\n",
    "    print(f'total_val_loss: {total_val_loss/len(dl_val):.5f}, val MSE: {total_val_mse/len(dl_val):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(76.9706)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((ds_val.fs[ds_val.fs!=100] - ds_val.fs[ds_val.fs!=100].mean())**2)**0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43873 30785 13088\n"
     ]
    }
   ],
   "source": [
    "# naive train test split\n",
    "with open('results.txt', 'r') as f, open('train.txt', 'a+') as f_tr, open('val.txt', 'a+') as f_val:\n",
    "    for line in f.readlines():\n",
    "        if np.random.rand() <= .7:\n",
    "            f_tr.write(line)\n",
    "        else:\n",
    "            f_val.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n",
      "s5\n"
     ]
    }
   ],
   "source": [
    "all_fs, all_seqs, all_spk_id = [], [], []\n",
    "with open('results.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        val_dict = eval(line)\n",
    "        all_seqs.append(torch.IntTensor(val_dict['units']))\n",
    "        all_fs.append(torch.FloatTensor(val_dict['f0']))\n",
    "        name = val_dict['audio'].split('_')[0]\n",
    "        if name in spk_id_dict:\n",
    "            all_spk_id.append(torch.IntTensor([spk_id_dict[name]]))\n",
    "        else:\n",
    "            print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}